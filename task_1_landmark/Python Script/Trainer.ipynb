{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries & Setup Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ANSUMAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import ColorJitter, RandomAffine, RandomPerspective\n",
    "from torchvision import models\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Error Handling\n",
    "try:\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "except ImportError:\n",
    "    from contextlib import contextmanager\n",
    "    @contextmanager\n",
    "    def autocast(enabled=True):\n",
    "        yield\n",
    "    class GradScaler:\n",
    "        def scale(self, loss):\n",
    "            return loss\n",
    "        def unscale_(self, optimizer):\n",
    "            pass\n",
    "        def step(self, optimizer):\n",
    "            optimizer.step()\n",
    "        def update(self):\n",
    "            pass\n",
    "\n",
    "# Set Current Working Directory\n",
    "from pathlib import Path\n",
    "project_root = Path.cwd().parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Data Augmentations and Helper Functions\n",
    "Implementation of the random_horizontal_flip and random_rotation functions to apply data augmentation on images and landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_horizontal_flip(image, landmarks, p=0.5):\n",
    "    \"\"\"Flip the image and landmarks horizontally with probability p.\"\"\"\n",
    "    if random.random() < p:\n",
    "        image = image.transpose(method=Image.FLIP_LEFT_RIGHT)\n",
    "        w = image.width\n",
    "        landmarks[:, 0] = w - landmarks[:, 0]\n",
    "    return image, landmarks\n",
    "\n",
    "def random_rotation(image, landmarks, max_angle=15):\n",
    "    \"\"\"Rotate the image and landmarks by a random angle in [-max_angle, max_angle].\"\"\"\n",
    "    angle = random.uniform(-max_angle, max_angle)\n",
    "    image = image.rotate(angle, resample=Image.BILINEAR)\n",
    "    w, h = image.width, image.height\n",
    "    cx, cy = w / 2, h / 2\n",
    "    angle_rad = -math.radians(angle)\n",
    "    rot_matrix = np.array([\n",
    "        [math.cos(angle_rad), -math.sin(angle_rad)],\n",
    "        [math.sin(angle_rad), math.cos(angle_rad)]\n",
    "    ])\n",
    "    landmarks = landmarks - np.array([cx, cy], dtype=np.float32)\n",
    "    landmarks = np.dot(landmarks, rot_matrix.T)\n",
    "    landmarks = landmarks + np.array([cx, cy], dtype=np.float32)\n",
    "    return image, landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing FetalLandmarkDataset and Data Loading\n",
    "Create the FetalLandmarkDataset class to read image paths and landmarks from CSV, apply resizing, augmentations, and use DataLoader for training and validation splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 622\n",
      "Train: 497, Val: 62\n"
     ]
    }
   ],
   "source": [
    "class FetalLandmarkDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Reads ultrasound images and landmark ground-truth from a CSV.\n",
    "    The CSV must have:\n",
    "      image_name, ofd_1_x, ofd_1_y, ofd_2_x, ofd_2_y,\n",
    "                  bpd_1_x, bpd_1_y, bpd_2_x, bpd_2_y\n",
    "    Applies resizing, advanced data augmentation, and returns:\n",
    "      - image: Tensor of shape [3, H, W]\n",
    "      - landmarks: Tensor of shape [4, 2]\n",
    "    \"\"\"\n",
    "    def __init__(self, images_dir, csv_file, image_size=(256, 256), augment=True):\n",
    "        self.images_dir = images_dir\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.image_size = image_size\n",
    "        self.augment = augment\n",
    "\n",
    "        self.extra_transforms = T.Compose([\n",
    "            ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "            RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "            RandomPerspective(distortion_scale=0.4, p=0.5),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_name = row['image_name']\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        landmarks = np.array([\n",
    "            [row['ofd_1_x'], row['ofd_1_y']],\n",
    "            [row['ofd_2_x'], row['ofd_2_y']],\n",
    "            [row['bpd_1_x'], row['bpd_1_y']],\n",
    "            [row['bpd_2_x'], row['bpd_2_y']]\n",
    "        ], dtype=np.float32)\n",
    "        orig_w, orig_h = image.size\n",
    "        target_w, target_h = self.image_size\n",
    "        scale_x, scale_y = target_w / orig_w, target_h / orig_h\n",
    "        landmarks[:, 0] *= scale_x\n",
    "        landmarks[:, 1] *= scale_y\n",
    "        image = image.resize(self.image_size, resample=Image.BILINEAR)\n",
    "\n",
    "        if self.augment:\n",
    "            image, landmarks = random_horizontal_flip(image, landmarks, p=0.5)\n",
    "            image, landmarks = random_rotation(image, landmarks, max_angle=15)\n",
    "            image = self.extra_transforms(image)\n",
    "\n",
    "        image = T.ToTensor()(image)\n",
    "        return image, torch.tensor(landmarks, dtype=torch.float)\n",
    "\n",
    "# Paths and dataset split\n",
    "images_dir = project_root / \"Dataset\" / \"Images\"\n",
    "csv_file = project_root / \"Dataset\" / \"role_challenge_dataset_ground_truth.csv\"\n",
    "full_dataset = FetalLandmarkDataset(images_dir, csv_file, image_size=(256, 256), augment=True)\n",
    "total_samples = len(full_dataset)\n",
    "train_size = int(0.8 * total_samples)\n",
    "val_size = int(0.1 * total_samples)\n",
    "test_size = total_samples - train_size - val_size\n",
    "train_dataset, val_dataset, _ = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "# Disable augmentation on validation\n",
    "val_dataset.dataset.augment = False\n",
    "print(f\"Total samples: {total_samples}\")\n",
    "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}\")\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition: ResNet34 Landmark Model\n",
    "Define the ResNet34LandmarkModel by modifying the last layer of a pretrained ResNet34 to output 8 coordinates (4 (x,y) pairs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ANSUMAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ANSUMAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet34LandmarkModel(\n",
      "  (backbone): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=512, out_features=8, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ResNet34LandmarkModel(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(ResNet34LandmarkModel, self).__init__()\n",
    "        self.backbone = models.resnet34(pretrained=pretrained)\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Linear(in_features, 8)  # 8 coords => 4 (x,y) pairs\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.backbone(x)\n",
    "        return out.view(-1, 4, 2)\n",
    "\n",
    "# Instantiate the model and move it to the device\n",
    "model = ResNet34LandmarkModel(pretrained=True).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop and Early Stopping Implementation\n",
    "Implement the training loop that uses MSELoss, Adam optimizer, and CosineAnnealingLR scheduler, along with early stopping and model weight saving when validation loss improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 3e-4\n",
    "epochs = 60\n",
    "patience = 10\n",
    "\n",
    "# Training Loop with Early Stopping and Model Weight Saving\n",
    "def train_landmark_model(model, train_loader, val_loader, epochs, device, patience):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    best_val_loss = float(\"inf\")\n",
    "    no_improve_count = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for images, landmarks in train_loader:\n",
    "            images = images.to(device)\n",
    "            landmarks = landmarks.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(images)\n",
    "            loss = criterion(preds, landmarks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images_val, landmarks_val in val_loader:\n",
    "                images_val = images_val.to(device)\n",
    "                landmarks_val = landmarks_val.to(device)\n",
    "                preds_val = model(images_val)\n",
    "                loss_val = criterion(preds_val, landmarks_val)\n",
    "                val_loss += loss_val.item()\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1:02d}: Train Loss {avg_train_loss:.4f}, Val Loss {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Save model weights if validation loss improves\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            no_improve_count = 0\n",
    "            torch.save(model.state_dict(), project_root / \"Model Weights\" / \"hypothesis_best_model_weights.pth\")\n",
    "        else:\n",
    "            no_improve_count += 1\n",
    "            if no_improve_count >= patience:\n",
    "                print(\"Early Stopping Triggered.\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Training\n",
    "Run the training phase by initializing the training loop with provided hyperparameters and printing out the training details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "train_landmark_model(model, train_loader, val_loader, epochs=epochs, device=device, patience=patience)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
